{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = '/Users/admin/Documents/PhD/Code/perceptual-tuning-results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment for development/debugging\n",
    "#%matplotlib inline\n",
    "\n",
    "\n",
    "# Uncomment to plot finalized figures\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"pgf\")\n",
    "pgf_with_custom_preamble = {\n",
    "    \"font.family\": \"serif\", # use serif/main font for text elements\n",
    "    \"text.usetex\": True,    # use inline math for ticks\n",
    "    \"pgf.rcfonts\": False,   # don't setup fonts from rc parameters\n",
    "    \"pgf.preamble\": [\n",
    "         \"\\\\usepackage{unicode-math}\",  # unicode math setup\n",
    "         \"\\\\setmainfont{Doulos SIL}\" # serif font via preamble\n",
    "         ]\n",
    "}\n",
    "mpl.rcParams.update(pgf_with_custom_preamble)\n",
    "\n",
    "\n",
    "from scone_phobia.utils.apply_analyses import fetch_data\n",
    "import scone_phobia.metadata.add_metadata as add_metadata\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path as path\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions to aggregate data to obtain an error rate for each available (contrast x test set) level in 4 conditions:\n",
    "#  Jap. native/Am. Eng. native/Read native/Spontaneous native\n",
    "\n",
    "def agg_res(df, dependent_var, df_is_resampled=False):\n",
    "    \"\"\"\n",
    "    Aggregate results to contrast either model with different \"training language\"\n",
    "    or different \"training register\", by setting the level of 'dependent_var'\n",
    "    accordingly.\n",
    "    \"\"\"\n",
    "    groupby_cols = [dependent_var, 'model type', 'contrast', 'test language', 'test register']\n",
    "    if df_is_resampled:\n",
    "        # ensure separate analysis for each resample\n",
    "        groupby_cols = groupby_cols + ['batch ID', 'batch size', 'boot ID']\n",
    "    agg_df = df.groupby(groupby_cols, as_index=False).mean()\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "def split_levels(df, dependent_var, levels):\n",
    "    # aggregate results and split them according to 'levels' of 'dependent_var'\n",
    "    df_agg = agg_res(df, dependent_var)\n",
    "    dfs = {}\n",
    "    for level in levels:\n",
    "        dfs[level] = df_agg[df_agg[dependent_var] == level]\n",
    "    return dfs   \n",
    "        \n",
    "\n",
    "def merge_dfs(dfs, on, suffixes):\n",
    "    # a limited extension of pandas.merge able to merge any number of dataframes\n",
    "    # recursive (more readable than an iterative version with reduce)\n",
    "    assert len(dfs) >= 2\n",
    "    if len(dfs) == 2:\n",
    "        res_df = pandas.merge(dfs[0], dfs[1], on=on, suffixes=suffixes)\n",
    "    else:\n",
    "        right_df = merge_dfs(dfs[1:], on, suffixes[1:])\n",
    "        left_df = dfs[0]\n",
    "        suffix = suffixes[0]\n",
    "        for col in left_df:\n",
    "            if not(col in on):\n",
    "                # add suffix\n",
    "                left_df[col + suffix] = left_df[col]\n",
    "                del left_df[col]\n",
    "        res_df = pandas.merge(left_df, right_df, on=on, suffixes=['', ''])\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def groupby_testset_contrast(df, langs, regs, suffixes):\n",
    "    merge_cols = [\"contrast\", \"test language\", \"model type\", 'test register']\n",
    "    dfs_trainlang = split_levels(df, \"training language\", langs)\n",
    "    dfs_trainreg = split_levels(df, \"training register\", regs)\n",
    "    data = [dfs_trainlang[lang] for lang in langs] + [dfs_trainreg[reg] for reg in regs]\n",
    "    suffixes = [suffixes[lang] for lang in langs] + [suffixes[reg] for reg in regs]\n",
    "    res_df = merge_dfs(data, on=merge_cols, suffixes=suffixes)\n",
    "    return res_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading minimal-pair errors\n",
    "\n",
    "mp_folder = root + 'ABX/mp_scores'\n",
    "\n",
    "# select relevant models\n",
    "dpgmm = 'dpgmm_novtln_vad'\n",
    "percTun_filt = lambda mp_fname: 'AMtri1_sat_small_LMtri1satsmall' in mp_fname\\\n",
    "                                  or 'mfcc_novtln' in mp_fname\\\n",
    "                                  or dpgmm in mp_fname\n",
    "\n",
    "# get raw minimal-pair discriminatione errors (without any resampling for now)\n",
    "dummy = lambda x: x\n",
    "df = fetch_data(dummy, mp_folder, filt=percTun_filt, add_metadata=add_metadata.language_register)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "langs = ['American English', 'Japanese']\n",
    "regs = ['Read', 'Spontaneous']\n",
    "suffixes = {'American English': \"_AE\",\n",
    "            'Japanese': \"_Jap\",\n",
    "            'Read': \"_read\",\n",
    "            'Spontaneous': \"_spont\"}\n",
    "data = groupby_testset_contrast(df, langs, regs, suffixes)\n",
    "\n",
    "# filter out silences\n",
    "def not_sil(contrast, silences):\n",
    "    p1, p2 = contrast.split(\"-\")\n",
    "    return not(p1 in silences) and not(p2 in silences)\n",
    "\n",
    "silences = ['NSN', 'SPN', 'SIL']\n",
    "data = data[[not_sil(con, silences) for con in data['contrast']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do that before...\n",
    "#del data['training language_AE']\n",
    "#del data['training language_Jap']\n",
    "#del data['training register_spont']\n",
    "#del data['training register_read']\n",
    "\n",
    "d_l = data[['model type', 'contrast', 'test language', 'test register']].copy()\n",
    "d_l['native advantage'] = [e_Jap-e_AE if test_lang == 'American English' else e_AE-e_Jap for test_lang, e_AE, e_Jap in zip(data['test language'], data['error_AE'], data['error_Jap'])]\n",
    "d_l['native parameter'] = 'language'\n",
    "\n",
    "d_r = data[['model type', 'contrast', 'test language', 'test register']].copy()\n",
    "d_r['native advantage'] = [e_spont-e_read if test_reg == 'Read' else e_read-e_spont for test_reg, e_read, e_spont in zip(data['test register'], data['error_read'], data['error_spont'])]\n",
    "d_r['native parameter'] = 'register'\n",
    "\n",
    "data2 = pandas.concat([d_l, d_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1142 read speech\n",
    "# 1293 spontaneous speech\n",
    "len(np.unique(data2['contrast']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some quick stats\n",
    "rr = data2[(data2['native parameter'] == 'register') & (data2['model type'] == 'dpgmm_novtln_vad')]\n",
    "\n",
    "\n",
    "len(np.where(rr['native advantage'] >= 0)[0]) / float(len(rr))\n",
    "# Read: 52.9772; 70.1401\n",
    "# Spontaneous: 44.7796; 51.1988\n",
    "# AE: 71.0315; 80.7608\n",
    "# Jap.  69.4757; 82.9588\n",
    "\n",
    "# register > 0\n",
    "# 0.4862422997946612\n",
    "# register < 0\n",
    "# 0.3991786447638604\n",
    "# register == 0\n",
    "# 0.11457905544147844\n",
    "\n",
    "#>=0 0.6008213552361397\n",
    "\n",
    "# language > 0\n",
    "# 0.7034907597535934\n",
    "# language < 0\n",
    "# 0.18275154004106775\n",
    "# language == 0\n",
    "# 0.1137577002053388\n",
    "\n",
    "#>=0 0.8172484599589322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "g = sns.catplot(data=data2, x='test register', y='native advantage', hue='native parameter', row='test language', col='model type', kind='boxen',\n",
    "                col_order=['dpgmm_novtln_vad', 'AMtri1_sat_small_LMtri1satsmall'], legend=False, aspect=.7)\n",
    "\n",
    "g.set_xlabels('Test stimuli\\'s register', fontsize=18)\n",
    "for ax in g.axes.flatten():\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(23)\n",
    "\n",
    "\n",
    "for i, axes_row in enumerate(g.axes):\n",
    "    for j, ax in enumerate(axes_row):\n",
    "        if i==1:\n",
    "            ax.set_xticklabels(['Read', 'Spont.'], fontsize=23)\n",
    "            ax.set_title('')\n",
    "        if j==0:\n",
    "            ax.set_ylabel('$\\Delta$ABX error rate (in \\%)', fontsize=23)\n",
    "        if i==0:\n",
    "            if j==0:\n",
    "                ax.set_title('GMM\\n(unsupervised)', fontsize=23)\n",
    "            else:\n",
    "                ax.set_title('HMM\\n(supervised)', fontsize=23)\n",
    "        ax.set_xlim([-.4, 1.4])\n",
    "        ax.grid(axis='y')   \n",
    "        ax.tick_params(axis='both', which='both', width=0, length=0)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.plot([-.4, 1.4], [0, 0], 'k-')\n",
    "g.despine(left=True)\n",
    "          \n",
    "     \n",
    "         \n",
    "g.fig.tight_layout()\n",
    "g.savefig(root + 'ABX/figures/native_advantage_supp.pdf')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main figure\n",
    "\n",
    "g = sns.catplot(data=data2, x='model type', y='native advantage', col='native parameter', kind='boxen', sharey=True,\n",
    "                order=['dpgmm_novtln_vad'], hue='native parameter', dodge=False, aspect=.6)\n",
    "\n",
    "labs = ['Native language\\nadvantage', \"`Native register\\'\\nadvantage\"]\n",
    "#g.set_yticklabels('\\Delta', fontsize=20)  # '$\\Delta$ABX error rate (in \\%)'\n",
    "\n",
    "for tick in g.axes[0,0].yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(23)\n",
    "\n",
    "for i, (ax, lab) in enumerate(zip(g.axes.flatten(), labs)):\n",
    "    ax.xaxis.set_ticks([])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title(lab, fontsize=23)\n",
    "    ax.set_ylim([-20, 20])\n",
    "    ax.set_xlim([-.4, .4])\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('$\\Delta$ABX error rate (in \\%)', fontsize=23)\n",
    "    ax.tick_params(axis='both', which='both', width=0, length=0)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.plot([-.4, .4], [0, 0], 'k-')\n",
    "    ax.grid(axis='y')\n",
    "g.despine(left=True, bottom=True)\n",
    "\n",
    "g.fig.tight_layout()\n",
    "g.savefig(root + 'ABX/figures/native_advantage_main.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
