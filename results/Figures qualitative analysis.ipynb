{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = '/Users/admin/Documents/PhD/Code/perceptual-tuning-results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures qualitative analysis (phonetic categoriness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment for development/debugging\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "inline_plots=True\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment to plot finalized figures\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"pgf\")\n",
    "pgf_with_custom_preamble = {\n",
    "    \"font.family\": \"serif\", # use serif/main font for text elements\n",
    "    \"text.usetex\": True,    # use inline math for ticks\n",
    "    \"pgf.rcfonts\": False,   # don't setup fonts from rc parameters\n",
    "    \"pgf.preamble\": [\n",
    "         \"\\\\usepackage{unicode-math}\",  # unicode math setup\n",
    "         \"\\\\setmainfont{Doulos SIL}\" # serif font via preamble\n",
    "         ]\n",
    "}\n",
    "mpl.rcParams.update(pgf_with_custom_preamble)\n",
    "inline_plots=False\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_data=True\n",
    "nb_unq_dur=46  # 0 (no correction for misalignment control) or 46 (ms)\n",
    "\n",
    "if cleaned_data:\n",
    "    nb_unq = pd.read_csv(root + 'no_phon_cats/results/nb_unq_within_spk_cleaned.txt')\n",
    "else:\n",
    "    nb_unq = pd.read_csv(root + 'no_phon_cats/results/nb_unq.txt')\n",
    "nb_unq = nb_unq[nb_unq['dur'] == nb_unq_dur]\n",
    "    \n",
    "nb_cat = pd.read_csv(root + 'no_phon_cats/results/nb_cat.txt')\n",
    "dur = pd.read_csv(root + 'no_phon_cats/results/dur.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(dur, nb_cat, nb_unq):\n",
    "    dur, nb_cat, nb_unq = dur.copy(), nb_cat.copy(), nb_unq.copy()\n",
    "    dur['duration'] = 1000*dur['duration']\n",
    "    del dur['Unnamed: 0']\n",
    "    del dur['info']\n",
    "    del dur['test']\n",
    "    dur = dur.rename(columns={'duration': 'y', 'unit': 'id'})\n",
    "    dur['measure type'] = 'duration'\n",
    "\n",
    "\n",
    "    del nb_cat['Unnamed: 0']\n",
    "    nb_cat = nb_cat.rename(columns={'nb cat': 'y'})\n",
    "    nb_cat['measure type'] = 'nb cat'\n",
    "    nb_cat['id'] = 0\n",
    "\n",
    "\n",
    "    del nb_unq['Unnamed: 0']\n",
    "    del nb_unq['test']\n",
    "    del nb_unq['dur']\n",
    "    del nb_unq['count type']\n",
    "    nb_unq = nb_unq.rename(columns={'nunique': 'y', 'word_trans': 'id'})\n",
    "\n",
    "    d = {by: df for by, df in nb_unq.groupby('by_spk')}\n",
    "    nb_unq_within, nb_unq_across = [d[True], d[False]]\n",
    "    del nb_unq_within['by_spk']\n",
    "    del nb_unq_across['by_spk']\n",
    "    nb_unq_within['measure type'] = 'nb unq within'\n",
    "    nb_unq_across['measure type'] = 'nb unq across'\n",
    "    data = pd.concat([nb_cat, dur, nb_unq_within, nb_unq_across])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = prepare_data(dur, nb_cat, nb_unq)\n",
    "\n",
    "# keep only one baseline\n",
    "data = data[(data['model'] == 'GMM') | \n",
    "            ((data['model'] != 'GMM') & ([e in ['WSJ', 'GPJ'] for e in data['train']]))]\n",
    "def cond(e, f):\n",
    "    if f == 'GMM':\n",
    "        return 'GMM (read)' if e in ['WSJ', 'GPJ'] else 'GMM (spont.)'\n",
    "    elif f == 'HMM-phone':\n",
    "        return 'Phoneme recognizer baseline'\n",
    "    else:\n",
    "        return 'Phone-state baseline'\n",
    "\n",
    "data['test lang'] = ['AE' if e in ['WSJ', 'BUC'] else 'JP' for e in data['train']]\n",
    "data['cond'] = [cond(e, f) for e, f in zip(data['train'], data['model'])]\n",
    "del data['train']\n",
    "\n",
    "\n",
    "colors = [\"white\", \"white\", \"dusty pink\"]\n",
    "my_palette = seaborn.xkcd_palette(colors)\n",
    "g = seaborn.catplot(data=data, y='y', x='cond', col='measure type', row='test lang',\n",
    "                    kind='bar', sharey=False, order=['GMM (read)', 'GMM (spont.)', 'Phoneme recognizer baseline'],\n",
    "                    palette=my_palette)\n",
    "\n",
    "edge_colors = [\"xkcd:putty\", \"xkcd:putty\", \"xkcd:dusty pink\"]\n",
    "title = [\"Number of\\nlearned units\", \"Duration\\n of activation\", \"Acoustic (in)variance\\n(within speaker)\", \"Acoustic (in)variance\\n(across speaker)\"]\n",
    "ylab = [\"No. units\", \"Duration (ms)\", \"No. distinct units\\n for 10 repetitions\", \"No. of distinct units\\nfor 10 repetitions\"]\n",
    "xlab = []  #[\"Read speech model\", \"Spont. speech model\", \"Phoneme recognizer\\n(supervised baseline)\"]\n",
    "g.set_xticklabels(xlab, rotation=45, ha='right', fontsize=15)\n",
    "for i, row in enumerate(g.axes):\n",
    "    for j, axis in enumerate(row):\n",
    "        axis.set_ylabel(ylab[j], fontsize=25)\n",
    "        axis.set_xlabel('')\n",
    "        for tick in axis.yaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(25) \n",
    "        for tick in axis.xaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(20) \n",
    "        if i == 0:\n",
    "            axis.set_title(title[j], fontsize=25)\n",
    "        else:\n",
    "            axis.set_title('')\n",
    "        patches = [e for e in axis.get_children() if isinstance(e, mpl.patches.Rectangle)]\n",
    "        for color, patch in zip(edge_colors, patches):\n",
    "            patch.set_edgecolor(color)\n",
    "            patch.set_linewidth(3)\n",
    "        if j == 0:\n",
    "            axis.set_ylim([0, 1000])\n",
    "            #axis.set_yscale('log')\n",
    "        if j == 1:\n",
    "            axis.set_ylim([0, 100])\n",
    "        if j in [2, 3]:\n",
    "            if nb_unq_dur==0:\n",
    "                axis.set_ylim([1, 10])\n",
    "                axis.set_yticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "            else:\n",
    "                axis.set_ylim([1, 4])\n",
    "                axis.set_yticks([1, 2, 3, 4])\n",
    "\n",
    "# Define some hatches\n",
    "hatches = ['\\\\', '.', '', '\\\\', '*', 'o']\n",
    "\n",
    "# Loop over the bars\n",
    "for axis in g.axes.flatten():\n",
    "    for i,thisbar in enumerate(axis.patches):\n",
    "        # Set a different hatch for each bar\n",
    "        thisbar.set_hatch(hatches[i])\n",
    "\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis='both', which='both', width=0, length=0)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis='y')   \n",
    "#g.despine(left=True)\n",
    "\n",
    "g.fig.tight_layout()\n",
    "if not(inline_plots):\n",
    "    if cleaned_data:\n",
    "        if nb_unq_dur == 0:\n",
    "            out=root + \"no_phon_cats/figures/main_cleaned_nomisalignmentcorrection.pdf\"\n",
    "        else:\n",
    "            out=root + \"no_phon_cats/figures/main_cleaned.pdf\"\n",
    "    else:\n",
    "        if nb_unq_dur == 0:\n",
    "            out=root + \"no_phon_cats/figures/main_nomisalignmentcorrection.pdf\"\n",
    "        else:\n",
    "            out=root + \"no_phon_cats/figures/main.pdf\"\n",
    "    g.savefig(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = [\"white\", \"white\", \"dusty pink\", \"blue grey\"]\n",
    "my_palette = seaborn.xkcd_palette(colors)\n",
    "g = seaborn.catplot(data=data, y='y', x='cond', col='measure type', row='test lang',\n",
    "                    kind='bar', sharey=False, order=['GMM (read)', 'GMM (spont.)', 'Phoneme recognizer baseline',\n",
    "                                                     'Phone-state baseline'],\n",
    "                    palette=my_palette)\n",
    "\n",
    "edge_colors = [\"xkcd:putty\", \"xkcd:putty\", \"xkcd:dusty pink\", \"xkcd:blue grey\"]\n",
    "title = [\"Number of\\nlearned units\", \"Duration\\n of activation\", \"Acoustic (in)variance\\n(within speaker)\", \"Acoustic (in)variance\\n(across speaker)\"]\n",
    "ylab = [\"No. units\", \"Duration (ms)\", \"No. distinct units\\n for 10 repetitions\", \"No. of distinct units\\nfor 10 repetitions\"]\n",
    "xlab = []  #[\"Read speech model\", \"Spont. speech model\", \"Phoneme recognizer\\n(supervised baseline)\"]\n",
    "g.set_xticklabels(xlab, rotation=45, ha='right', fontsize=15)\n",
    "for i, row in enumerate(g.axes):\n",
    "    for j, axis in enumerate(row):\n",
    "        axis.set_ylabel(ylab[j], fontsize=25)\n",
    "        axis.set_xlabel('')\n",
    "        for tick in axis.yaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(25) \n",
    "        for tick in axis.xaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(20) \n",
    "        if i == 0:\n",
    "            axis.set_title(title[j], fontsize=25)\n",
    "        else:\n",
    "            axis.set_title('')\n",
    "        patches = [e for e in axis.get_children() if isinstance(e, mpl.patches.Rectangle)]\n",
    "        for color, patch in zip(edge_colors, patches):\n",
    "            patch.set_edgecolor(color)\n",
    "            patch.set_linewidth(3)\n",
    "        if j == 0:\n",
    "            axis.set_ylim([0, 3000])\n",
    "            #axis.set_yscale('log')\n",
    "        if j == 1:\n",
    "            axis.set_ylim([0, 100])\n",
    "        if j in [2, 3]:\n",
    "            if nb_unq_dur==0:\n",
    "                axis.set_ylim([1, 10])\n",
    "                axis.set_yticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "            else:\n",
    "                axis.set_ylim([1, 4])\n",
    "                axis.set_yticks([1, 2, 3, 4])\n",
    "\n",
    "# Define some hatches\n",
    "hatches = ['\\\\', '.', '', '', '*', 'o']\n",
    "\n",
    "# Loop over the bars\n",
    "for axis in g.axes.flatten():\n",
    "    for i,thisbar in enumerate(axis.patches):\n",
    "        # Set a different hatch for each bar\n",
    "        thisbar.set_hatch(hatches[i])\n",
    "        \n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis='both', which='both', width=0, length=0)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis='y')   \n",
    "#g.despine(left=True)\n",
    "        \n",
    "g.fig.tight_layout()\n",
    "if not(inline_plots):\n",
    "    if cleaned_data:\n",
    "        if nb_unq_dur == 0:\n",
    "            out=root + \"no_phon_cats/figures/supp_cleaned_nomisalignmentcorrection.pdf\"\n",
    "        else:\n",
    "            out=root + \"no_phon_cats/figures/supp_cleaned.pdf\"\n",
    "    else:\n",
    "        if nb_unq_dur == 0:\n",
    "            out=root + \"no_phon_cats/figures/supp_nomisalignmentcorrection.pdf\"\n",
    "        else:               \n",
    "            out=root + \"no_phon_cats/figures/supp.pdf\"\n",
    "    g.savefig(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1-2h models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data_small(dur, nb_cat, nb_unq):\n",
    "    dur, nb_cat, nb_unq = dur.copy(), nb_cat.copy(), nb_unq.copy()\n",
    "    dur['duration'] = 1000*dur['duration']\n",
    "    del dur['Unnamed: 0']\n",
    "    #del dur['info']\n",
    "    del dur['test']\n",
    "    dur = dur.rename(columns={'duration': 'y', 'unit': 'id'})\n",
    "    dur['subcorpus'] = [int(e.split('_')[-1]) for e in dur['train']]\n",
    "    dur['train'] = [e.split('_')[0] for e in dur['train']]\n",
    "    dur['measure type'] = 'duration'\n",
    "\n",
    "\n",
    "    del nb_cat['Unnamed: 0']\n",
    "    nb_cat = nb_cat.rename(columns={'nb cat': 'y', 'train subset': 'subcorpus'})\n",
    "    nb_cat['measure type'] = 'nb cat'\n",
    "    nb_cat['id'] = 0\n",
    "\n",
    "    for i in range(1,11):\n",
    "        del nb_unq[i]['Unnamed: 0']\n",
    "        del nb_unq[i]['test']\n",
    "        del nb_unq[i]['dur']\n",
    "        del nb_unq[i]['count type']\n",
    "        assert all([int(e.split('_')[-1])==i for e in nb_unq[i]['train']])\n",
    "        nb_unq[i]['train'] = [e.split('_')[0] for e in nb_unq[i]['train']]\n",
    "        nb_unq[i]['subcorpus'] = i\n",
    "        nb_unq[i] = nb_unq[i].rename(columns={'nunique': 'y', 'word_trans': 'id'})\n",
    "    nb_unq = pd.concat(nb_unq.values())\n",
    "\n",
    "    d = {by: df for by, df in nb_unq.groupby('by_spk')}\n",
    "    nb_unq_within, nb_unq_across = [d[True], d[False]]\n",
    "    del nb_unq_within['by_spk']\n",
    "    del nb_unq_across['by_spk']\n",
    "    nb_unq_within['measure type'] = 'nb unq within'\n",
    "    nb_unq_across['measure type'] = 'nb unq across'\n",
    "    data = pd.concat([nb_cat, dur, nb_unq_within, nb_unq_across])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_data=True\n",
    "nb_unq_dur=46  # use 46 or 0 for control with no correction for misalignment \n",
    "\n",
    "if cleaned_data:\n",
    "    nb_unq = {i: pd.read_csv(root + 'no_phon_cats_1h/results/nb_unq_within_spk_cleaned_{}.txt'.format(i))\n",
    "              for i in range(1,11)}\n",
    "else:\n",
    "    nb_unq = {i: pd.read_csv(root + 'no_phon_cats_1h/results/nb_unq_{}.txt'.format(i))\n",
    "              for i in range(1,11)}\n",
    "nb_unq = {i: nb_unq[i][nb_unq[i]['dur'] == nb_unq_dur] for i in range(1,11)}\n",
    "\n",
    "nb_cat = pd.read_csv(root + 'no_phon_cats_1h/results/nb_cat.txt')\n",
    "dur = pd.read_csv(root + 'no_phon_cats_1h/results/dur.txt')\n",
    "\n",
    "\n",
    "if cleaned_data:\n",
    "    nb_unq_full = pd.read_csv(root + 'no_phon_cats/results/nb_unq_within_spk_cleaned.txt')\n",
    "else:\n",
    "    nb_unq_full = pd.read_csv(root + 'no_phon_cats/results/nb_unq.txt')\n",
    "nb_unq_full = nb_unq_full[nb_unq_full['dur'] == nb_unq_dur]\n",
    "    \n",
    "nb_cat_full = pd.read_csv(root + 'no_phon_cats/results/nb_cat.txt')\n",
    "dur_full = pd.read_csv(root + 'no_phon_cats/results/dur.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = prepare_data_small(dur, nb_cat, nb_unq)\n",
    "\n",
    "def cond(e, f):\n",
    "    return 'GMM (read) 1-2h' if e in ['WSJ', 'GPJ'] else 'GMM (spont.) 1-2h'\n",
    "\n",
    "data['test lang'] = ['AE' if e in ['WSJ', 'BUC'] else 'JP' for e in data['train']]\n",
    "data['cond'] = [cond(e, f) for e, f in zip(data['train'], data['model'])]\n",
    "del data['train']\n",
    "\n",
    "# Average data over the 10 subcorpus\n",
    "data_avg = data.groupby(['id', 'measure type', 'y', 'test lang', 'cond'], as_index=False).mean()\n",
    "del data_avg['subcorpus']\n",
    "\n",
    "# Also get full models\n",
    "data_full = prepare_data(dur_full, nb_cat_full, nb_unq_full)\n",
    "\n",
    "# keep only one baseline\n",
    "data_full = data_full[(data_full['model'] == 'GMM') | \n",
    "            ((data_full['model'] != 'GMM') & ([e in ['WSJ', 'GPJ'] for e in data_full['train']]))]\n",
    "def cond(e, f):\n",
    "    if f == 'GMM':\n",
    "        return 'GMM (read)' if e in ['WSJ', 'GPJ'] else 'GMM (spont.)'\n",
    "    elif f == 'HMM-phone':\n",
    "        return 'Phoneme recognizer baseline'\n",
    "    else:\n",
    "        return 'Phone-state baseline'\n",
    "\n",
    "data_full['test lang'] = ['AE' if e in ['WSJ', 'BUC'] else 'JP' for e in data_full['train']]\n",
    "data_full['cond'] = [cond(e, f) for e, f in zip(data_full['train'], data_full['model'])]\n",
    "del data_full['train']\n",
    "\n",
    "\n",
    "full_data = pd.concat([data_avg, data_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if nb_unq_dur == 0:\n",
    "    corder = ['nb unq within', 'nb unq across']\n",
    "else:\n",
    "    corder = ['nb cat', 'duration', 'nb unq within', 'nb unq across']\n",
    "\n",
    "colors = [\"white\", \"white\", \"white\", \"white\", \"dusty pink\"]\n",
    "my_palette = seaborn.xkcd_palette(colors)\n",
    "g = seaborn.catplot(data=full_data, y='y', x='cond', col='measure type', row='test lang',\n",
    "                    kind='bar', sharey=False, order=['GMM (read)', 'GMM (spont.)',\n",
    "                                                     'GMM (read) 1-2h', 'GMM (spont.) 1-2h',\n",
    "                                                     'Phoneme recognizer baseline'],\n",
    "                    col_order=corder,\n",
    "                    palette=my_palette)\n",
    "\n",
    "edge_colors = [\"xkcd:putty\", \"xkcd:putty\", \"xkcd:baby blue\", \"xkcd:baby blue\", \"xkcd:dusty pink\"]\n",
    "if nb_unq_dur == 0:\n",
    "    title = [\"Acoustic (in)variance\\n(within speaker)\", \"Acoustic (in)variance\\n(across speaker)\"]\n",
    "    ylab = [\"No. distinct units\\n for 10 repetitions\", \"No. of distinct units\\nfor 10 repetitions\"]\n",
    "else:\n",
    "    title = [\"Number of\\nlearned units\", \"Duration\\n of activation\", \"Acoustic (in)variance\\n(within speaker)\", \"Acoustic (in)variance\\n(across speaker)\"]\n",
    "    ylab = [\"No. units\", \"Duration (ms)\", \"No. distinct units\\n for 10 repetitions\", \"No. of distinct units\\nfor 10 repetitions\"]\n",
    "xlab = []  #[\"Read speech model\", \"Spont. speech model\", \"Phoneme recognizer\\n(supervised baseline)\"]\n",
    "g.set_xticklabels(xlab, rotation=45, ha='right', fontsize=15)\n",
    "for i, row in enumerate(g.axes):\n",
    "    for j, axis in enumerate(row):\n",
    "        axis.set_ylabel(ylab[j], fontsize=25)\n",
    "        axis.set_xlabel('')\n",
    "        for tick in axis.yaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(25) \n",
    "        for tick in axis.xaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(20) \n",
    "        if i == 0:\n",
    "            axis.set_title(title[j], fontsize=25)\n",
    "        else:\n",
    "            axis.set_title('')\n",
    "        patches = [e for e in axis.get_children() if isinstance(e, mpl.patches.Rectangle)]\n",
    "        for color, patch in zip(edge_colors, patches):\n",
    "            patch.set_edgecolor(color)\n",
    "            patch.set_linewidth(3)\n",
    "        if nb_unq_dur==0:\n",
    "            axis.set_ylim([1, 8])\n",
    "            axis.set_yticks([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "        else:\n",
    "            if j == 0:\n",
    "                axis.set_ylim([0, 1000])\n",
    "                #axis.set_yscale('log')\n",
    "            if j == 1:\n",
    "                axis.set_ylim([0, 100])\n",
    "            if j in [2, 3]:\n",
    "                axis.set_ylim([1, 4])\n",
    "                axis.set_yticks([1, 2, 3, 4])\n",
    "\n",
    "# Define some hatches\n",
    "hatches = ['\\\\', '.', '\\\\', '.', '*', 'o']\n",
    "\n",
    "# Loop over the bars\n",
    "for axis in g.axes.flatten():\n",
    "    for i,thisbar in enumerate(axis.patches):\n",
    "        # Set a different hatch for each bar\n",
    "        thisbar.set_hatch(hatches[i])\n",
    "\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis='both', which='both', width=0, length=0)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis='y')   \n",
    "#g.despine(left=True)\n",
    "\n",
    "g.fig.tight_layout()\n",
    "if not(inline_plots):\n",
    "    if cleaned_data:\n",
    "        if nb_unq_dur==0:\n",
    "            out=root + \"no_phon_cats_1h/figures/main_cleaned_nomisalignmentcorrection.pdf\"\n",
    "        else:\n",
    "            out=root + \"no_phon_cats_1h/figures/main_cleaned.pdf\"\n",
    "    else:\n",
    "        if nb_unq_dur==0:\n",
    "            out=root + \"no_phon_cats_1h/figures/main_nomisalignmentcorrection.pdf\"\n",
    "        else:\n",
    "            out=root + \"no_phon_cats_1h/figures/main.pdf\"\n",
    "    g.savefig(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
