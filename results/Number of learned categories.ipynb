{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = '/Users/admin/Documents/PhD/Code/perceptual-tuning-results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment for development/debugging\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Uncomment to plot finalized figures\n",
    "\"\"\"\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"pgf\")\n",
    "pgf_with_custom_preamble = {\n",
    "    \"font.family\": \"serif\", # use serif/main font for text elements\n",
    "    \"text.usetex\": True,    # use inline math for ticks\n",
    "    \"pgf.rcfonts\": False,   # don't setup fonts from rc parameters\n",
    "    \"pgf.preamble\": [\n",
    "         \"\\\\usepackage{unicode-math}\",  # unicode math setup\n",
    "         \"\\\\setmainfont{Doulos SIL}\" # serif font via preamble\n",
    "         ]\n",
    "}\n",
    "mpl.rcParams.update(pgf_with_custom_preamble)\n",
    "\"\"\"\n",
    "\n",
    "import scipy.io as io\n",
    "import os.path as path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Load GMM model saved in .mat from Jason Chang's library\n",
    "    Output: \n",
    "        Dictionary with entries:\n",
    "            cov : array of floats (n_components,dim,dim)\n",
    "                Contains the computed covariance matrices of the mixture.\n",
    "            \n",
    "            means : array of floats (n_components,dim)\n",
    "                Contains the computed means of the mixture.\n",
    "            \n",
    "            log_weights : array of floats (n_components,)\n",
    "    \"\"\"\n",
    "    # file format is not consistent between Chang's init and update steps...\n",
    "    data = io.loadmat(filename)\n",
    "    sh = data['clusters'].shape\n",
    "    if sh[0] == 1:\n",
    "        K = sh[1]\n",
    "        #dt = data['clusters'].dtype.descr\n",
    "        #keys = [dt[i][0] for i in range(len(dt))]  # names of various descriptors for clusters\n",
    "        model = {}        \n",
    "        logpi = [data['clusters'][0,i]['logpi'] for i in range(K)]\n",
    "        model['log_weights'] = np.concatenate(logpi).reshape((K,))  # (K,)\n",
    "        mu = [data['clusters'][0,i]['mu'] for i in range(K)]\n",
    "        model['means'] = np.column_stack(mu).T  # (K,d)\n",
    "        d = model['means'].shape[1]\n",
    "        Sigma = [data['clusters'][0,i]['Sigma'].reshape((1,d,d)) for i in range(K)]\n",
    "        model['cov'] = np.concatenate(Sigma, axis=0)  # (K,d,d)\n",
    "    else:\n",
    "        K = sh[0]\n",
    "        model = {}        \n",
    "        logpi = [data['clusters'][i,0]['logpi'] for i in range(K)]\n",
    "        model['log_weights'] = np.concatenate(logpi).reshape((K,))  # (K,)\n",
    "        mu = [data['clusters'][i,0]['mu'] for i in range(K)]\n",
    "        model['means'] = np.column_stack(mu).T  # (K,d)\n",
    "        d = model['means'].shape[1]\n",
    "        Sigma = [data['clusters'][i,0]['Sigma'].reshape((1,d,d)) for i in range(K)]\n",
    "        model['cov'] = np.concatenate(Sigma, axis=0)  # (K,d,d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_GMM_cat(model_folder, corpora):\n",
    "    nb_cat = {}\n",
    "    nb_cat_small_models = {}\n",
    "    for corpus in corpora:\n",
    "        model_file = path.join(model_folder, corpus+'_1501-final.mat')\n",
    "        model = load_model(model_file)\n",
    "        nb_cat[corpus] = len(model['log_weights'])\n",
    "        nb_cat_small_models[corpus] = []\n",
    "        for i in range(1, 11):\n",
    "            model_file = path.join(model_folder, corpus+'_10_{}'.format(i))\n",
    "            model = load_model(model_file)\n",
    "            nb_cat_small_models[corpus].append(len(model['log_weights']))\n",
    "    return nb_cat, nb_cat_small_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nlines(filename):\n",
    "    with open(filename, 'r') as fh:\n",
    "        return len(fh.readlines())\n",
    "\n",
    "\n",
    "def get_nitems(filename):\n",
    "    with open(filename, 'r') as fh:\n",
    "        lines = fh.readlines()\n",
    "    assert len(lines) == 1\n",
    "    return len(lines[0].strip().split())\n",
    "\n",
    "\n",
    "def get_sup_cat(activation_folder, corpora):\n",
    "    nb_cat = {'nb cat': [], 'train': [], 'model': []}\n",
    "    test_corpora = {'BUC': 'WSJ', 'CSJ': 'GPJ', 'WSJ': 'WSJ', 'GPJ': 'GPJ'}\n",
    "    for corpus in corpora:\n",
    "        test_corpus = test_corpora[corpus]\n",
    "        model = 'hmm_phone'\n",
    "        filename = path.join(activation_folder, 'activation_{}_{}_skip0_basic_{}_info.txt'.format(corpus, test_corpus, model))\n",
    "        nb_cat['nb cat'].append(get_nitems(filename))\n",
    "        nb_cat['train'].append(corpus)\n",
    "        nb_cat['model'].append('HMM-phone')\n",
    "        model = 'hmm_state'\n",
    "        filename = path.join(activation_folder, 'activation_{}_{}_skip0_basic_{}_info.txt'.format(corpus, test_corpus, model))\n",
    "        nb_cat['nb cat'].append(get_nlines(filename))\n",
    "        nb_cat['train'].append(corpus)\n",
    "        nb_cat['model'].append('HMM-state')\n",
    "    return nb_cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpora = ['BUC', 'WSJ', 'CSJ', 'GPJ']\n",
    "nb_cat_GMM, nb_cat_small_models_GMM = get_GMM_cat(root + 'no_phon_cats/models/', corpora)\n",
    "\n",
    "corpora = ['WSJ', 'GPJ', 'BUC', 'CSJ']\n",
    "nb_cat = get_sup_cat(root + 'no_phon_cats/unit_activation/', corpora)\n",
    "\n",
    "for corpus in nb_cat_GMM:\n",
    "    nb_cat['nb cat'].append(nb_cat_GMM[corpus])\n",
    "    nb_cat['train'].append(corpus)\n",
    "    nb_cat['model'].append('GMM')\n",
    "nb_cat = pd.DataFrame(nb_cat)\n",
    "nb_cat.to_csv(root + '/no_phon_cats/results/nb_cat.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Nb_cat.txt for 1-2h models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpora = ['BUC', 'WSJ', 'CSJ', 'GPJ']\n",
    "nb_cat_GMM, nb_cat_small_models_GMM = get_GMM_cat(root + 'no_phon_cats_1h/models/', corpora)\n",
    "\n",
    "nb_cat_small = {'model': [], 'nb cat': [], 'train': [], 'train subset': []}\n",
    "for corpus in nb_cat_small_models_GMM:\n",
    "    for i, nb in enumerate(nb_cat_small_models_GMM[corpus]):\n",
    "        nb_cat_small['nb cat'].append(nb)\n",
    "        nb_cat_small['train'].append(corpus)\n",
    "        nb_cat_small['train subset'].append(i+1)\n",
    "        nb_cat_small['model'].append('GMM')\n",
    "nb_cat_small = pd.DataFrame(nb_cat_small)\n",
    "nb_cat_small.to_csv(root + 'no_phon_cats_1h/results/nb_cat.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nb cat as a function of iteration number for all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nb_cat(model_folder, corpus, split_factor, subset, nb_iter):\n",
    "    if nb_iter==1501:\n",
    "        it = '1501-final'\n",
    "    else:\n",
    "        it = str(nb_iter)\n",
    "    fname = '_'.join([corpus, str(split_factor), str(subset), it]) + '.mat'\n",
    "    model_file = path.join(model_folder, fname)\n",
    "    model = load_model(model_file)\n",
    "    return len(model['log_weights'])\n",
    "\n",
    "\n",
    "corpora = ['BUC', 'WSJ', 'CSJ', 'GPJ']\n",
    "split_factors = [1, 10, 100, 1000]\n",
    "subsets = {1 : [1],\n",
    "           10 : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "           100 : [1, 11, 21, 31, 41, 51, 61, 71, 81, 91],\n",
    "           1000 : [1, 101, 201, 301, 401, 501, 601, 701, 801, 901]}\n",
    "nb_iters = [1, 21, 61, 141, 301, 621, 1261, 1501]     \n",
    "\n",
    "df = {'nb_cat': [], 'train': [], 'split_factor': [], 'subset': [], 'nb_iter': []}\n",
    "for corpus in corpora:\n",
    "    for split in split_factors:\n",
    "        for subset in subsets[split]:\n",
    "            for nb_iter in nb_iters:\n",
    "                df['nb_cat'].append(get_nb_cat(root + 'convergence/models/', corpus, split, subset, nb_iter))\n",
    "                df['train'].append(corpus)\n",
    "                df['split_factor'].append(split)\n",
    "                df['subset'].append(subset)\n",
    "                df['nb_iter'].append(nb_iter)\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(root + 'convergence/results/nb_cat.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
