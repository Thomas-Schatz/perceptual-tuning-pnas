{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = '/Users/admin/Documents/PhD/Code/perceptual-tuning-results/'\n",
    "\n",
    "mp_folder = root + 'ABX/mp_scores'\n",
    "\n",
    "analysis_folder = root + 'ABX/analyses/avg_error/resampling'\n",
    "\n",
    "fig_path = root + 'ABX/figures/avg.pdf'\n",
    "\n",
    "fig_robustness_path = root + 'ABX/figures/avg_robustness.pdf'\n",
    "\n",
    "fig_baselines_ path = root + 'ABX/figures/avg_baselines.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment for development/debugging\n",
    "#%matplotlib inline\n",
    "\n",
    "\n",
    "# Uncomment to plot finalized figures\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"pgf\")\n",
    "pgf_with_custom_preamble = {\n",
    "    \"font.family\": \"serif\", # use serif/main font for text elements\n",
    "    \"text.usetex\": True,    # use inline math for ticks\n",
    "    \"pgf.rcfonts\": False,   # don't setup fonts from rc parameters\n",
    "    \"pgf.preamble\": [\n",
    "         \"\\\\usepackage{unicode-math}\",  # unicode math setup\n",
    "         \"\\\\setmainfont{Doulos SIL}\" # serif font via preamble\n",
    "         ]\n",
    "}\n",
    "mpl.rcParams.update(pgf_with_custom_preamble)\n",
    "\n",
    "\n",
    "from scone_phobia import apply_analysis\n",
    "from scone_phobia.utils.mp_scores import estimate_std\n",
    "from scone_phobia.analyses.avg_error import avg_error\n",
    "import scone_phobia.metadata.add_metadata as add_metadata\n",
    "from scone_phobia.plots.catplot import custom_catplot\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specialise the generic avg_error analysis a little (averaging over 4 conditions and over C and V scores). To avoid any issue of dependency that could arise when aggregating estimates of variability of our error estimates, we apply the resampling directly over the specialised analysis. This is also necessary to perform permutation tests.\n",
    "\n",
    "We cache the resampling results at the level of the output of the generic avg_error analysis though, as the specialised analysis is not costly to apply to resamples and would require writing a dedicated caching scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading (or computing if it's the first time) avg_error analysis results with full resamples\n",
    "\n",
    "\n",
    "# select relevant models\n",
    "dpgmm = 'dpgmm_novtln_vad'\n",
    "percTun_filt = lambda mp_fname: 'AMtri1_sat_small_LMtri1satsmall' in mp_fname\\\n",
    "                                  or 'mfcc_novtln' in mp_fname\\\n",
    "                                  or dpgmm in mp_fname\n",
    "\n",
    "# launch analyses with cached resampling\n",
    "analysis = avg_error\n",
    "df_avg, boot_df_avg = apply_analysis(analysis, mp_folder,\n",
    "                                     filt=percTun_filt,\n",
    "                                     add_metadata=add_metadata.language_register,\n",
    "                                     resampling=True,\n",
    "                                     resample_caching_scheme='mp_file',\n",
    "                                     analysis_folder=analysis_folder,\n",
    "                                     pickle_encoding=None,\n",
    "                                     resampled_pickle_encoding=\"latin1\",\n",
    "                                     verbose=0)\n",
    "\n",
    "# we're going to do further aggregation on errors that might have some dependencies\n",
    "# so we have no use for the resampled standard deviation estimates for the current errors\n",
    "del df_avg['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Average results into 4 conditions \n",
    "# based on match between language and register across training and test sets\n",
    "\n",
    "def get_traintest_match(df_row=None):\n",
    "    if df_row is None:\n",
    "        # return col names for condition\n",
    "        return ['train/test match']\n",
    "    else:\n",
    "        # return list of values computed from df_row\n",
    "        cols = ['training set', 'test set',\n",
    "                'training language', 'test language',\n",
    "                'training register', 'test register']\n",
    "        x, y, lx, ly, rx, ry = [df_row[e] for e in cols]\n",
    "        if x == 'None' or y == 'None':\n",
    "            rel = 'NA'  # not applicable\n",
    "        elif x == y:\n",
    "            rel = 'same C'  # same corpus\n",
    "        elif lx == ly and rx != ry:\n",
    "            rel = 'same L diff R'\n",
    "        elif rx == ry and lx != ly:\n",
    "            rel = 'diff L same R'\n",
    "        elif lx == ly and rx == ry:\n",
    "            rel = 'same L same R'\n",
    "        else:\n",
    "            rel = 'diff L diff R'\n",
    "        return [rel]\n",
    "\n",
    "\n",
    "# We also look at full 16 conditions for each training set/test set combination (for extended data)\n",
    "def get_full_condition(df_row=None):\n",
    "    cols = ['training language', 'test language',\n",
    "            'training register', 'test register']\n",
    "    if df_row is None:\n",
    "        # return col names for condition\n",
    "        return cols\n",
    "    else:\n",
    "        # return list of values computed from df_row\n",
    "        return [df_row[col] for col in cols]\n",
    "\n",
    "\n",
    "def agg_conds(df, get_condition, df_is_resampled=False):\n",
    "    df = df.copy(deep=True)  # we're adding columns, so make a copy\n",
    "    cond_cols = get_condition()\n",
    "    cond_data = zip(*[get_condition(row) for _, row in df.iterrows()])\n",
    "    for col, col_data in zip(cond_cols, cond_data):\n",
    "        df[col] = col_data\n",
    "    groupby_cols = ['model type', 'contrast type'] + cond_cols\n",
    "    if df_is_resampled:\n",
    "        # ensure separate analysis for each resample\n",
    "        groupby_cols = groupby_cols + ['batch ID', 'batch size', 'boot ID']\n",
    "    agg_df = df.groupby(groupby_cols, as_index=False).mean()\n",
    "    return cond_cols, agg_df\n",
    "\n",
    "cond_cols_agg, df_agg = agg_conds(df_avg, get_traintest_match)\n",
    "_, boot_df_agg = agg_conds(boot_df_avg, get_traintest_match, df_is_resampled=True)\n",
    "\n",
    "\n",
    "cond_cols_control, df_control = agg_conds(df_avg, get_full_condition)\n",
    "_, boot_df_control = agg_conds(boot_df_avg, get_full_condition, df_is_resampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (C + V) / 2\n",
    "def avg_C_V(df, cond_cols, df_is_resampled=False):\n",
    "    res_df = df[[e in['C', 'V'] for e in df['contrast type']]]\n",
    "    groupby_cols = ['model type'] + cond_cols\n",
    "    if df_is_resampled:\n",
    "        # ensure separate analysis for each resample\n",
    "        groupby_cols = groupby_cols + ['batch ID', 'batch size', 'boot ID']\n",
    "    res_df = res_df.groupby(groupby_cols, as_index=False).mean()\n",
    "    return res_df\n",
    "\n",
    "df = avg_C_V(df_agg, cond_cols_agg)\n",
    "boot_df = avg_C_V(boot_df_agg, cond_cols_agg, df_is_resampled=True)\n",
    "\n",
    "df_control = avg_C_V(df_control, cond_cols_control)\n",
    "boot_df_control = avg_C_V(boot_df_control, cond_cols_control, df_is_resampled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get estimate of standard deviations\n",
    "df = estimate_std(df, boot_df)\n",
    "df_control = estimate_std(df_control, boot_df_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_order = [dpgmm]\n",
    "col_labels = ['']\n",
    "x_order = ['same C', 'same L diff R', 'diff L same R', 'diff L diff R']\n",
    "xticklabels = ['Same language\\n Same register', 'Same language\\n Different register',\n",
    "               'Different language\\n Same register', 'Different language\\n Different register']\n",
    "err_args = {'ecolor': 'k',\n",
    "            'capsize': 2,\n",
    "            'elinewidth': 2,\n",
    "            'markeredgewidth': 2}\n",
    "# colors courtesy of Marianne\n",
    "# my_red, my_blue = (0.85, .325, .098, 1), (0, .447, .741, 1)\n",
    "my_red, my_blue = 'r', 'b' \n",
    "\n",
    "# main part\n",
    "palette={e : (my_red if 'diff L' in e else my_blue) for e in df['train/test match']}\n",
    "g, x_dict = custom_catplot(x='train/test match', y=\"error\", yerr=\"std\",\n",
    "                           col=\"model type\",\n",
    "                           data=df,\n",
    "                           kind=\"bar\",\n",
    "                           err_args=err_args,\n",
    "                           order=x_order,\n",
    "                           col_order=col_order,\n",
    "                           legend=False,\n",
    "                           palette=palette)\n",
    "\n",
    "\n",
    "# labels, fontsize etc. \n",
    "g.set_xticklabels(xticklabels, rotation=45, ha='right', fontsize=15)\n",
    "for tick in g.axes[0,0].yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20)\n",
    "g.set_ylabels('ABX error rate (in \\%)', fontsize=20)\n",
    "g.set_xlabels('Train/Test relationship', fontsize=20)\n",
    "for ax, t in zip(g.axes.flatten(), col_labels):\n",
    "    ax.tick_params(axis='both', which='both', width=0, length=0)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis='y')\n",
    "    ax.set_title(t, fontsize=25)\n",
    "g.despine(left=True)\n",
    "# y range set to half that for fig2?\n",
    "g.axes[0,0].set_ylim([0, 11])\n",
    "g.axes[0,0].set_xlim([-.48, 3.48])\n",
    "    \n",
    "\n",
    "g.savefig(fig_path)\n",
    "# legend: blue is matched language, red mismatched language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure showing robustness of the results across training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_res_robustness(data, model_type, fig_path=None, ymax=16):\n",
    "    # Select only dpgmm data\n",
    "    df = data[data[\"model type\"] == model_type]\n",
    "    facet_labels = [\"Read American English test\", \"Read Japanese test\",\n",
    "                    \"Spont. American English test\", \"Spont. Japanese test\"]  # row by row\n",
    "    col_order = [\"American English\", \"Japanese\"]\n",
    "    row_order = [\"Read\", \"Spontaneous\"]\n",
    "    x_order = ['Read', 'Spontaneous']\n",
    "    hue_order = [\"American English\", \"Japanese\"]\n",
    "    xticklabels = [\"Read training\", \"Spont. training\"]\n",
    "    err_args = {'ecolor': 'k',\n",
    "                'capsize': 2,\n",
    "                'elinewidth': 2,\n",
    "                'markeredgewidth': 2}\n",
    "    # colors courtesy of Marianne\n",
    "    # my_red, my_blue = (0.85, .325, .098, 1), (0, .447, .741, 1)\n",
    "    my_red, my_blue = 'r', 'b' \n",
    "\n",
    "    # main part\n",
    "    palette={'American English': 'b', 'Japanese': 'g'}\n",
    "    #palette = {e : (my_red if 'diff L' in e else my_blue) for e in df['condition']}\n",
    "    g, x_dict = custom_catplot(x=\"training register\", y=\"error\", yerr=\"std\",\n",
    "                               order=x_order,\n",
    "                               col=\"test language\",\n",
    "                               col_order=col_order,\n",
    "                               row=\"test register\",\n",
    "                               row_order=row_order,\n",
    "                               hue=\"training language\",\n",
    "                               hue_order=hue_order,\n",
    "                               data=df,\n",
    "                               kind=\"bar\",\n",
    "                               err_args=err_args,\n",
    "                               legend=False,\n",
    "                               sharex=False,\n",
    "                               palette=palette)\n",
    "\n",
    "    # labels, fontsize etc. \n",
    "    g.set_xticklabels(xticklabels, fontsize=15)\n",
    "    for axes in g.axes:\n",
    "        for tick in axes[0].yaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(20)\n",
    "    g.set_ylabels('ABX error rate (in \\%)', fontsize=18)\n",
    "    g.set_xlabels('Training register', fontsize=18)\n",
    "    for ax, t in zip(g.axes.flatten(), facet_labels):\n",
    "        ax.tick_params(axis='both', which='both', width=0, length=0)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.grid(axis='y')\n",
    "        ax.set_title(t, fontsize=20)\n",
    "        ax.set_xlim([-.48, 1.48])\n",
    "        ax.set_ylim([0, ymax])\n",
    "    g.despine(left=True)\n",
    "    g.fig.tight_layout()\n",
    "\n",
    "    if not(fig_path is None):\n",
    "        g.savefig(fig_path)\n",
    "    # legend: blue is AE, red Jap. for training language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_res_robustness(df_control, dpgmm, fig_path=fig_robustness_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Figure: with baseline and topline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Break down into MFCC baseline and other scores for plot\n",
    "mfcc_df = df[df[\"model type\"] == 'mfcc_novtln']\n",
    "mfcc_err, mfcc_std = float(mfcc_df['error']), float(mfcc_df['std'])\n",
    "main_df = df[df[\"model type\"] != 'mfcc_novtln']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Figure\n",
    "col_order = [dpgmm, 'AMtri1_sat_small_LMtri1satsmall']\n",
    "col_labels = ['GMM (unsupervised)', 'HMM (supervised)']\n",
    "x_order = ['same C', 'same L diff R', 'diff L same R', 'diff L diff R']\n",
    "xticklabels = ['Same language\\n Same register', 'Same language\\n Different register',\n",
    "               'Different language\\n Same register', 'Different language\\n Different register']\n",
    "err_args = {'ecolor': 'k',\n",
    "            'capsize': 2,\n",
    "            'elinewidth': 2,\n",
    "            'markeredgewidth': 2}\n",
    "# colors courtesy of Marianne\n",
    "# my_red, my_blue = (0.85, .325, .098, 1), (0, .447, .741, 1)\n",
    "my_red, my_blue = 'r', 'b' \n",
    "\n",
    "# main part\n",
    "palette={e : (my_red if 'diff L' in e else my_blue) for e in df['train/test match']}\n",
    "g, x_dict = custom_catplot(x=\"train/test match\", y=\"error\", yerr=\"std\",\n",
    "                           col=\"model type\",\n",
    "                           data=main_df,\n",
    "                           kind=\"bar\",\n",
    "                           err_args=err_args,\n",
    "                           order=x_order,\n",
    "                           col_order=col_order,\n",
    "                           legend=False,\n",
    "                           palette=palette)\n",
    "# baseline\n",
    "for ax in g.axes.flatten():\n",
    "    mi, ma = ax.get_xlim()\n",
    "    # plot dotted line\n",
    "    line = ax.plot([mi, ma], [mfcc_err, mfcc_err], 'k--')\n",
    "    # put in background\n",
    "    line[0].set_zorder(0)\n",
    "    # add error-bands\n",
    "    rect = patches.Rectangle((mi,mfcc_err-mfcc_std), ma-mi, 2*mfcc_std,\n",
    "                              edgecolor=(.8, .8, .8, 1),\n",
    "                              facecolor=(.8, .8, .8, 1))\n",
    "    # put error-bands in background\n",
    "    rect.set_zorder(0)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "# labels, fontsize etc. \n",
    "g.set_xticklabels(xticklabels, rotation=45, ha='right', fontsize=15)\n",
    "for tick in g.axes[0,0].yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20)\n",
    "g.set_ylabels('ABX error rate (in \\%)', fontsize=20)\n",
    "g.set_xlabels('Train/Test relationship', fontsize=20)\n",
    "for ax, t in zip(g.axes.flatten(), col_labels):\n",
    "    ax.tick_params(axis='both', which='both', width=0, length=0)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis='y')\n",
    "    ax.set_title(t, fontsize=25)\n",
    "g.despine(left=True)\n",
    "# y range set to half that for fig2?\n",
    "g.axes[0,0].set_ylim([0, 15])\n",
    "g.axes[0,0].set_xlim([-.48, 3.48])\n",
    "g.axes[0,1].set_xlim([-.48, 3.48])\n",
    "\n",
    "\n",
    "g.savefig(fig_baselines_path)\n",
    "# legend: blue is matched language, red mismatched language + black dotted line and grey"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
