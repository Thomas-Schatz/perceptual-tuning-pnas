{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_root = '/scratch1/users/thomas/perceptual-tuning-data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warnings\n",
    "\n",
    "This all assumes that wave filenames uniquely identify speakers and vice-versa (i.e. one wavefile per speaker).\n",
    "\n",
    "I'm not sure the ordering of speakers in the subcorpora (or even in the original corpus) make sense. This is not a problem clearly for DPGMM, but this might be a factor for other type of models. I'm not sure if we want to define meaningful orderings independently of models and then do model comparison using those or if we should make ad hoc decisions on ordering for each model. The former makes more sense if we are seeing this as modeling a temporally ordered environment.\n",
    "\n",
    "Also we kept even very very short segments. The procedure for generating the training data from the segments file should be robust to that.\n",
    "\n",
    "\n",
    "# Methods\n",
    "\n",
    "How to generate the appropriate smaller segments.txt from the initial one?\n",
    "\n",
    "Retained solution is to measure total duration for each speaker, and to divide it in *j* equal duration parts, keeping the initial ordering of utterances. This yield *j* independent datasets, with a subset-superset structure taking the form of a tree. The reason for doing this is to get smaller datasets where, as much as possible, the only difference with the large dataset is the duration. To keep all other factors constant, we make sure of having the same speakers and relative duration per speakers and having temporally ordered datasets.\n",
    "\n",
    "One thing we are not keeping constant is having fully-formed sentences. For small *j*'s this shouldn't have a large effect, as most sentence will remain fully formed. As *j* increases, however, this will eventually result in having less than one full utterance per speaker. For now, we just ignore this issue. I think the proper way to address it if it ever becomes important is to study the effect of the number of speakers and more generally of the distribution of speech amount per speaker independently of duration at the same time as we study the effect of total duration, using in particular small number of speakers with large amounts of data.\n",
    "\n",
    "Choice of *j*'s. Let's start with dividing sets by 10, 100 and 1000. We either have ~10h total from 20 different speakers (for spontaneous speech) or ~20h total from ~100 speakers (for read speech) of training data. This will result respectively in around ~1h, 6min, 36s total with on average 3min, 18s and 1.8s per speaker and ~2h, 12min, 72s total with on average 72s, 7.2s, 0.72s, per speaker. Then we can add more data-points wherever it seems interesting.\n",
    "\n",
    "To start with, let's use only min(j, 10) of the subsets. If j>10, we use the first subset (in temporal order) that is included in one of the j=10 subsets. With this approach, we can later add any *j* such that 10 divides *j* and keep the nice inclusion relationships. If we need smaller *j*'s, we should look at j=5 and j=2 to keep inclusions nice.\n",
    "\n",
    "Once we have the segments files for subcorpora, we generate .mat training files with appropriately selected subsets of the total data using the vad_file argument of h5f2mat.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This part is pretty generic and might form the basis for an independent module\n",
    "\n",
    "# Function to load base segments.txt\n",
    "\n",
    "def read_segs(vad_file):\n",
    "    utts = {'utt': [], 'spk': [], 'start': [], 'stop': [], 'duration': []}\n",
    "    with io.open(vad_file, 'r', encoding='utf-8') as fh:\n",
    "        for line in fh:\n",
    "            utt_id, wav_id, start, stop = line.strip().split(u\" \")\n",
    "            start, stop = float(start), float(stop)\n",
    "            utts['utt'].append(utt_id)\n",
    "            utts['spk'].append(wav_id[:-4])\n",
    "            utts['start'].append(start)\n",
    "            utts['stop'].append(stop)\n",
    "            utts['duration'].append(stop-start)\n",
    "    utts = pd.DataFrame(utts)\n",
    "    return utts\n",
    "\n",
    "\n",
    "# Functions to generate subcorpora segments files\n",
    "\n",
    "def get_subset_bounds(utts, speakers, nb_subsets):\n",
    "    # define each subset by its time boundaries\n",
    "    dur_per_spk = dict(utts.groupby('spk')['duration'].sum()) # in seconds\n",
    "    subsets = {}\n",
    "    for spk in speakers:\n",
    "        dur = dur_per_spk[spk]\n",
    "        for subset_id in range(nb_subsets):\n",
    "            subsets[spk, subset_id] = {'start': subset_id*dur/float(nb_subsets),\n",
    "                                       'stop': (subset_id+1)*dur/float(nb_subsets)}\n",
    "    return subsets\n",
    "\n",
    "\n",
    "def get_spk_subset_df(spk_df, start, stop):\n",
    "    # Start:\n",
    "    # - find first row with spk_amount_so_far strictly higher than start\n",
    "    # - drop any previous rows and replace start of this row with:\n",
    "    #         this_row_stop-(spk_amount_so_far_of_this_row-desired_start)\n",
    "    # Stop:\n",
    "    # - find first row with spk_amount_so_far higher or equal than stop (could be same row as for start)\n",
    "    # - drop any following rows and replace stop of this row with:\n",
    "    #         this_row_stop-(spk_amount_so_far_of_this_row-desired_stop)\n",
    "    row_start = np.searchsorted(spk_df['spk_amount_so_far'], start, side='right')\n",
    "    assert len(row_start) == 1\n",
    "    row_start = row_start[0]\n",
    "    row_stop = np.searchsorted(spk_df['spk_amount_so_far'], stop, side='left')\n",
    "    assert len(row_stop) == 1\n",
    "    row_stop = row_stop[0]\n",
    "    spk_df = spk_df.iloc[row_start:row_stop+1].copy() # using iloc is appropriate here + copy to modify it without side effects\n",
    "    start_col_ind = list(spk_df.columns).index('start')\n",
    "    stop_col_ind = list(spk_df.columns).index('stop')\n",
    "    spk_amount_col_ind = list(spk_df.columns).index('spk_amount_so_far')\n",
    "    spk_df.iat[0, start_col_ind] = spk_df.iat[0, stop_col_ind] - (spk_df.iat[0, spk_amount_col_ind] - start)\n",
    "    spk_df.iat[-1, stop_col_ind] = spk_df.iat[-1, stop_col_ind] - (spk_df.iat[-1, spk_amount_col_ind] - stop)\n",
    "    return spk_df\n",
    "\n",
    "\n",
    "def get_subset_dfs(utts, speakers, subset_bounds, nb_subsets):\n",
    "    \"\"\"\n",
    "    Generate an appropriate dataframe for each subset\n",
    "    \"\"\"\n",
    "    # We use a column containing the sum duration of all sentences\n",
    "    # by the same speaker so far (assuming utterances to be sorted\n",
    "    # in the order of occurence in time for each speaker). The current\n",
    "    # sentence is included.\n",
    "    utts['spk_amount_so_far'] = utts.groupby('spk')['duration'].cumsum()\n",
    "    dfs = {}\n",
    "    for subset_id in range(nb_subsets):\n",
    "        dfs[subset_id] = {}\n",
    "        for spk, spk_df in utts.groupby('spk'):\n",
    "            # find appropriate bounds\n",
    "            start, stop = subset_bounds[spk, subset_id]['start'], subset_bounds[spk, subset_id]['stop']\n",
    "            # generate subset df\n",
    "            subset_df = get_spk_subset_df(spk_df, start, stop)\n",
    "            dfs[subset_id][spk] = subset_df\n",
    "        # concatenate dataframe for each spk in order determined by speakers\n",
    "        dfs[subset_id] = pd.concat([dfs[subset_id][spk] for spk in speakers])\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def save_subset_segfiles(subset_dfs, out_dir, res_id='segments'):\n",
    "    \"\"\"\n",
    "    Save the results in aptly named segments files\n",
    "    \"\"\"\n",
    "    nb_subsets = len(subset_dfs)\n",
    "    for subset_id in subset_dfs:\n",
    "        filename = path.join(out_dir, res_id + '__{}subsets__subset{}.txt'.format(nb_subsets, 1+subset_id))\n",
    "        df = subset_dfs[subset_id]\n",
    "        with io.open(filename, 'w', encoding='utf-8') as fh:\n",
    "            for _, row in df.iterrows():\n",
    "                fh.write(u\"{} {}.wav {} {}\\n\".format(row['utt'], row['spk'], row['start'], row['stop']))\n",
    "\n",
    "\n",
    "def generate_subcorpora(utts, nb_subsets, out_dir, res_id='segments'):\n",
    "    \"\"\"\n",
    "    Main function, splitting a corpus in nb_subsets parts as similar to the original corpus as possible\n",
    "    \"\"\"\n",
    "    # get an ordering for speakers\n",
    "    # (not sure if this is the same as in the original segments file, but order doesn't matter for GMM training at least)\n",
    "    speakers = [spk for spk, _ in utts.groupby('spk')]\n",
    "    subset_bounds = get_subset_bounds(utts, speakers, nb_subsets)\n",
    "    subset_dfs = get_subset_dfs(utts, speakers, subset_bounds, nb_subsets)\n",
    "    save_subset_segfiles(subset_dfs, out_dir, res_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This generates the subcorpora for our current setup.\n",
    "\n",
    "def load_segs(root, corpus):\n",
    "    if corpus == 'WSJ':\n",
    "        cocorpus = 'GPJ'\n",
    "    elif corpus == 'GPJ':\n",
    "        cocorpus = 'WSJ'\n",
    "    elif corpus == 'CSJ':\n",
    "        cocorpus = 'BUC'\n",
    "    elif corpus == 'BUC':\n",
    "        cocorpus = 'CSJ'\n",
    "    else:\n",
    "        assert False\n",
    "    vad_file = path.join(root, '{}/{}_matched_data_train/segments.txt')\n",
    "    vad_file = vad_file.format(corpus, cocorpus)\n",
    "    return read_segs(vad_file)\n",
    "\n",
    "# get j subset segments files for each j\n",
    "js = [10, 100, 1000]\n",
    "corpora = ['WSJ', 'BUC', 'GPJ', 'CSJ']\n",
    "root = base_root + 'corpora'\n",
    "\n",
    "for j in js:\n",
    "    for corpus in corpora:\n",
    "        out_dir = path.join(root, corpus, 'subcorpora')\n",
    "        # load target segments file\n",
    "        utts = load_segs(root, corpus)\n",
    "        generate_subcorpora(utts, j, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Results checks: distribution of number of sentences per speaker\n",
    "\n",
    "# original corpus\n",
    "plt.figure()\n",
    "for corpus in ['WSJ', 'BUC', 'GPJ', 'CSJ']:\n",
    "    utts = load_segs(root, corpus)\n",
    "    s = utts.groupby('spk').size()\n",
    "    print(np.min(s))\n",
    "    h = plt.hist(s, label=corpus)\n",
    "l = plt.legend()\n",
    "\n",
    "# a subcorpus\n",
    "nb_subsets = 10\n",
    "subset_id = 7  # 1-indexed here\n",
    "res_id = 'segments'\n",
    "plt.figure()\n",
    "for corpus in ['WSJ', 'BUC', 'GPJ', 'CSJ']:\n",
    "    out_dir = path.join(root, corpus, 'subcorpora')\n",
    "    seg_file = path.join(out_dir, res_id + '__{}subsets__subset{}.txt'.format(nb_subsets, subset_id))\n",
    "    utts = read_segs(seg_file)\n",
    "    s = utts.groupby('spk').size()\n",
    "    print(np.min(s))\n",
    "    h = plt.hist(s, label=corpus)\n",
    "l = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Results checks: distribution of number of 10ms frames per speaker, approximately\n",
    "\n",
    "# original corpus\n",
    "plt.figure()\n",
    "for corpus in ['WSJ', 'BUC', 'GPJ', 'CSJ']:\n",
    "    utts = load_segs(root, corpus)\n",
    "    f = utts.groupby('spk')['duration'].sum()*100\n",
    "    print(np.min(f))\n",
    "    h = plt.hist(f, label=corpus)\n",
    "l = plt.legend()\n",
    "\n",
    "# One subcorpus\n",
    "nb_subsets = 1000\n",
    "subset_id = 7  # 1-indexed here\n",
    "res_id = 'segments'\n",
    "plt.figure()\n",
    "for corpus in ['WSJ', 'BUC', 'GPJ', 'CSJ']:\n",
    "    out_dir = path.join(root, corpus, 'subcorpora')\n",
    "    seg_file = path.join(out_dir, res_id + '__{}subsets__subset{}.txt'.format(nb_subsets, subset_id))\n",
    "    utts = read_segs(seg_file)\n",
    "    f = utts.groupby('spk')['duration'].sum()*100\n",
    "    print(np.min(f))\n",
    "    h = plt.hist(f, label=corpus)\n",
    "l = plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
