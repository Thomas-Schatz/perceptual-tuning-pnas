# -*- coding: utf-8 -*-
"""
Created on Mon Jul 10 17:18:30 2017

@author: Thomas Schatz

Some code snippets used to perform some
informal sanity checks on forced alignments
generated by kaldi.
To be run manually.
"""

import numpy as np
import collections
import os.path as p


"""
def get_utt_ids(filename):
    utt_ids = set()
    with open(filename, 'r') as fh:
        lines = fh.readlines()
    for line in lines:
        utt_id = line.strip().split(" ")[0]
        utt_ids.add(utt_id)
    return utt_ids

root = '/Users/admin/Desktop'
align = p.join(root, './alignment_CSJ.txt')
text = p.join(root, './text_CSJ.txt')
u1 = get_utt_ids(align)
u2 = get_utt_ids(text)
"""
# check u1 included in u2
assert len(u2.difference(u1)) == len(u2)-len(u1)
# print missing sentences (failed alignment)
print(u2.difference(u1))

"""
def get_durs(filename, utts):
    dur = {}
    with open(filename, 'r') as fh:
        lines = fh.readlines()
    for line in lines:
        items = line.strip().split(" ")
        utt_id = items[0]
        if utt_id in utts:
            assert not(utt_id in dur)
            dur[utt_id] = float(items[3])-float(items[2])
    return dur

# check durations of sentences that were not aligned
dur = get_durs(p.join(root, './segments_CSJ.txt'), u2.difference(u1))
"""


def get_post(filename):
    posts = []
    phones = []
    with open(filename, 'r') as fh:
        lines = fh.readlines()
    for line in lines:
        #if line.strip().split(" ")[3] == '0.3077967':
        #    print(line)
        tokens =line.strip().split(" ")
        posts.append(float(tokens[3]))
        phones.append(tokens[4])
    return np.array(posts), np.array(phones)

posts, phones = get_post(p.join(root, './alignment_CSJ.txt'))
order = np.argsort(posts)
posts = posts[order]
phones = phones[order]

# check phone with low posterior probas
c=collections.Counter(phones[:100000])
c.most_common()
